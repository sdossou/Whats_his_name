{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdossou/Whats_his_name/blob/main/Whats_his_name_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \"What's His Name\" Application using LangGraph Tools\n",
        "\n",
        "\"What's His Name\" application allows a user to look up a famous person's name based on their characteristics.\n",
        "\n",
        "LangGraph is a tool that leverages LangChain Expression Language to build coordinated multi-actor and stateful applications that includes cyclic behaviour.\n",
        "\n",
        "This notebook uses the Wikidata and the Duck Duck Go Web Search tools.\n",
        "\n"
      ],
      "metadata": {
        "id": "gJXW_DgiSebM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies\n",
        "\n",
        "Installing relevant dependencies and setting API keys for openAI and LangSmith."
      ],
      "metadata": {
        "id": "3_fLDElOVoop"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaVwN269EttM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b17b199f-a871-4016-b6e8-27411c7709ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.1/96.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.6/86.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain langchain_openai langgraph wikibase-rest-api-client mediawikiapi duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdh8CoVWHRvs",
        "outputId": "44cd43ef-70fe-4e07-efe1-2fe1250cd0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"LangGraph Demo - {uuid4().hex[0:8]}\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv0glIDyHmRt",
        "outputId": "7e6567b0-2b66-4993-c214-b71cace0ab72"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangSmith API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tool Selection\n",
        "\n",
        "### Creating the Tool Belt\n",
        "\n",
        "Installing the agent with a toolbelt to help answer questions and add external knowledge with wikidata and Duck Duck Go Web Search.\n"
      ],
      "metadata": {
        "id": "sBRyQmEAVzua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.ddg_search import DuckDuckGoSearchRun\n",
        "from langchain_community.tools.wikidata.tool import WikidataAPIWrapper, WikidataQueryRun\n",
        "\n",
        "tool_belt = [DuckDuckGoSearchRun(), WikidataQueryRun(api_wrapper=WikidataAPIWrapper())]"
      ],
      "metadata": {
        "id": "lAxaSvlfIeOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Actioning with Tools\n",
        "\n",
        "Setting up the ToolExecutor to run the process."
      ],
      "metadata": {
        "id": "1FdOjEslXdRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import ToolExecutor\n",
        "\n",
        "tool_executor = ToolExecutor(tool_belt)"
      ],
      "metadata": {
        "id": "cFr1m80-JZsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model\n",
        "\n",
        "Setting-up the OpenAI model."
      ],
      "metadata": {
        "id": "VI-C669ZYVI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "QkNS8rNZJs4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binding the LangChain formatted tools to the model in an OpenAI function calling format."
      ],
      "metadata": {
        "id": "Ugkj3GzuZpQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.utils.function_calling import convert_to_openai_function\n",
        "\n",
        "functions = [convert_to_openai_function(t) for t in tool_belt]\n",
        "model = model.bind_functions(functions)"
      ],
      "metadata": {
        "id": "4OdMqFafZ_0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent State\n",
        "\n",
        "`coordinated multi-actor and stateful applications`\n",
        "\n",
        "\"stateful\" means that we want to have some kind of object which we can pass around our application that holds information about what the current situation (state) is. Since our system will be constructed of many parts moving in a coordinated fashion, we want to be able to ensure that we have some commonly understood idea of that state.\n",
        "\n",
        "LangGraph leverages a `StatefulGraph` which uses an `AgentState` object to pass information between the various nodes of the graph.\n",
        "\n",
        "This `AgentState` object is stored in a `TypedDict` with the key `messages` and the value is a `Sequence` of `BaseMessages` that will be appended to whenever the state changes.\n",
        "\n",
        "Let's think about a simple example to help understand exactly what this means:\n",
        "\n",
        "1. We initialize our state object:\n",
        "  - `{\"messages\" : []}`\n",
        "2. Our user submits a query to our application.\n",
        "  - New State: `HumanMessage(#1)`\n",
        "  - `{\"messages\" : [HumanMessage(#1)}`\n",
        "3. We pass our state object to an Agent node which is able to read the current state. It will use the last `HumanMessage` as input. It gets some kind of output which it will add to the state.\n",
        "  - New State: `AgentMessage(#1, additional_kwargs {\"function_call\" : \"WebSearchTool\"})`\n",
        "  - `{\"messages\" : [HumanMessage(#1), AgentMessage(#1, ...)]}`\n",
        "4. We pass our state object to a \"conditional node\" which reads the last state to determine if we need to use a tool - which it can determine properly because of our provided object"
      ],
      "metadata": {
        "id": "_296Ub96Z_H8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated, Sequence\n",
        "import operator\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[Sequence[BaseMessage], operator.add]"
      ],
      "metadata": {
        "id": "mxL9b_NZKUdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Setup\n",
        "\n",
        "Setting up the graph (nodes and edges) with the state, the tools and the LLM previously defined.\n"
      ],
      "metadata": {
        "id": "vWsMhfO9grLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import ToolInvocation\n",
        "import json\n",
        "from langchain_core.messages import FunctionMessage\n",
        "\n",
        "async def call_model(state):\n",
        "  messages = state[\"messages\"]\n",
        "  response = await model.ainvoke(messages)\n",
        "  return {\"messages\" : [response]}\n",
        "\n",
        "async def call_tool(state):\n",
        "  last_message = state[\"messages\"][-1]\n",
        "\n",
        "  action = ToolInvocation(\n",
        "      tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
        "      tool_input=json.loads(\n",
        "          last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
        "      )\n",
        "  )\n",
        "\n",
        "  response = await tool_executor.ainvoke(action)\n",
        "\n",
        "  function_message = FunctionMessage(content=str(response), name=action.tool)\n",
        "\n",
        "  return {\"messages\" : [function_message]}"
      ],
      "metadata": {
        "id": "91flJWtZLUrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining 2 nodes:\n",
        "\n",
        "- `call_model` is a node that calls the model\n",
        "- `call_tool` is a node which calls a tool\n",
        "\n"
      ],
      "metadata": {
        "id": "2bwR7MgWj3Wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "workflow.add_node(\"agent\", call_model)\n",
        "workflow.add_node(\"action\", call_tool)"
      ],
      "metadata": {
        "id": "_vF4_lgtmQNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding the entrypoint"
      ],
      "metadata": {
        "id": "uaXHpPeSnOWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.set_entry_point(\"agent\")"
      ],
      "metadata": {
        "id": "YGCbaYqRnmiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up a \"conditional edge\" which will use the output state of a node to determine which path to follow.\n",
        "\n",
        "Creating an edge where the origin node is the agent node and the destination node can be either the action node or the END (finish the graph).\n",
        "\n",
        "The dictionary passed in as the third parameter (the mapping) should be created with the possible outputs of our conditional function in mind. In this case `should_continue` outputs either `\"end\"` or `\"continue\"` which are subsequently mapped to the action node or the END node."
      ],
      "metadata": {
        "id": "0Q_pQgHmoW0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def should_continue(state):\n",
        "  last_message = state[\"messages\"][-1]\n",
        "\n",
        "  if \"function_call\" not in last_message.additional_kwargs:\n",
        "    return \"end\"\n",
        "\n",
        "  return \"continue\"\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    should_continue,\n",
        "    {\n",
        "        \"continue\" : \"action\",\n",
        "        \"end\" : END\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "1BZgb81VQf9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding the edge which connects the action node to the agent node closing the loop or cycle."
      ],
      "metadata": {
        "id": "yKCjWJCkrJb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.add_edge(\"action\", \"agent\")"
      ],
      "metadata": {
        "id": "UvcgbHf1rIXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the workflow"
      ],
      "metadata": {
        "id": "KYqDpErlsCsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "zt9-KS8DpzNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the Graph and Testing\n",
        "\n",
        "Testing the graph with a question that will trigger the wikidata tool."
      ],
      "metadata": {
        "id": "VEYcTShCsPaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "inputs = {\"messages\" : [HumanMessage(content=\"Who is the Spainish artist known for surrealist art in the 1920s?\")]}\n",
        "\n",
        "await app.ainvoke(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn4n37PQRPII",
        "outputId": "6986aaa3-7e1c-44fe-f1b5-c7c7be55eefc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Who is the Spainish artist known for surrealist art in the 1920s?'),\n",
              "  AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"Spanish artist known for surrealist art in the 1920s\"}', 'name': 'duckduckgo_search'}}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 168, 'total_tokens': 197}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'function_call', 'logprobs': None}),\n",
              "  FunctionMessage(content=\"Salvador Dalí (born May 11, 1904, Figueras, Spain—died January 23, 1989, Figueras) was a Spanish Surrealist painter and printmaker, influential for his explorations of subconscious imagery. Salvador Dalí and Man Ray. Salvador Dalí (left) and Man Ray, 1934. As an art student in Madrid and Barcelona, Dalí assimilated a vast number of ... Salvador Domingo Felipe Jacinto Dalí i Domènech, Marquess of Dalí of Púbol [a] gcYC (11 May 1904 - 23 January 1989), known as Salvador Dalí ( / ˈdɑːli, dɑːˈliː / DAH-lee, dah-LEE, [1] Catalan: [səlβəˈðo ðəˈli], Spanish: [salβaˈðoɾ ðaˈli] ), [b] was a Spanish surrealist artist renowned for his technical skill, precise ... Below, we celebrate 8 of the most famous Surrealist artists, whose artworks continue to fascinate audiences today. 1. Salvador Dali. Metamorphosis of Narcissus by Salvador Dalí, 1937, via Tate, London. The inimitable, flamboyant Spanish artist Salvador Dali is one of the most notable and notorious Surrealist artists. In this article, we shall discuss the life, legacy, and art of Spanish artist Salvador Dalí, who became a leading figure and icon of the Surrealist movement and one of the most important artists of the 20th century. Introduction. Salvador Dalí (1904-1989) was a prominent Spanish surrealist painter known for his eccentric and imaginative works. Known for his surrealistic paintings, eccentric personality, and boundless creativity, Dalí left an indelible mark on the art world. His unique blend of imagination, symbolism, and technical mastery made him a cultural ambassador for Spain and a representative of the country's artistic genius. ... He collaborated with other Spanish artists ...\", name='duckduckgo_search'),\n",
              "  AIMessage(content='The Spanish artist known for surrealist art in the 1920s is Salvador Dalí. He was a prominent Spanish Surrealist painter known for his eccentric and imaginative works. Dalí became a leading figure and icon of the Surrealist movement and one of the most important artists of the 20th century.', response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 653, 'total_tokens': 716}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})]}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at what happened:\n",
        "\n",
        "1. Our state object was populated with our request\n",
        "2. The state object was passed into our entry point (agent node) and the agent node added an `AIMessage` to the state object and passed it along the conditional edge\n",
        "3. The conditional edge received the state object, found the \"function_call\" `additional_kwarg`, and sent the state object to the action node\n",
        "4. The action node added the response from the OpenAI function calling endpoint to the state object and passed it along the edge to the agent node\n",
        "5. The agent node added a response to the state object and passed it along the conditional edge\n",
        "6. The conditional edge received the state object, could not find the \"function_call\" `additional_kwarg` and passed the state object to END where we see it output in the cell above!\n"
      ],
      "metadata": {
        "id": "DBHnUtLSscRr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing with the second tool Duck Duck Go Search"
      ],
      "metadata": {
        "id": "SRXfvOFKwpwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"messages\" : [HumanMessage(content=\"What is QLoRA in Machine Learning? Are their any papers that could help me understand?\")]}\n",
        "\n",
        "await app.ainvoke(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afv2BuEsV5JG",
        "outputId": "f3727837-328b-404a-b9a2-3514372ee703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='What is QLoRA in Machine Learning? Are their any papers that could help me understand?'),\n",
              "  AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"QLoRA in Machine Learning\"}', 'name': 'duckduckgo_search'}}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 169, 'total_tokens': 191}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'function_call', 'logprobs': None}),\n",
              "  FunctionMessage(content='Large Language Models (LLMs) are currently a hot topic in the field of machine learning. Imagine you\\'re an ML Engineer and your company has access to GPUs and open-source LLMs like LLAMA/Falcon. ... LoRA, Machine Learning, QLoRA, transformers. Categories: data-science, machine-learning. Updated: July 26, 2023. Share on Twitter Facebook ... Our results show that QLoRA finetuning on a small high-quality dataset leads to state-of-the-art results, even when using smaller models than the previous SoTA. We provide a detailed analysis of chatbot performance based on both human and GPT-4 evaluations showing that GPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Balancing this tradeoff is a key contribution of QLoRA. QLoRA. QLoRA (or Quantized Low-Rank Adaptation) combines 4 ingredients to get the most out of a machine\\'s limited memory without sacrificing model performance. I will briefly summarize key points from each. More details are available in the QLoRA paper [4]. Ingredient 1: 4-bit NormalFloat Unlock the power of QLoRA with our definitive guide! Learn how to fine-tune the Falcon-7b model using PEFT for optimal AI performance. Step into the future of machine learning today. \"Lora The Tuner\" By Daniel Warfield using MidJourney. All images by the author unless otherwise specified. Fine tuning is the process of tailoring a machine learning model to a specific application, which can be vital in achieving consistent and high quality performance.', name='duckduckgo_search'),\n",
              "  AIMessage(content=\"QLoRA (Quantized Low-Rank Adaptation) is a technique in machine learning that combines four ingredients to optimize a machine's limited memory without sacrificing model performance. It involves using 4-bit NormalFloat and fine-tuning on a small high-quality dataset to achieve state-of-the-art results.\\n\\nIf you are looking for papers to help you understand QLoRA better, you can refer to the QLoRA paper [4] for more detailed information on this technique.\", response_metadata={'token_usage': {'completion_tokens': 96, 'prompt_tokens': 530, 'total_tokens': 626}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})]}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is adapted from the notebook developed by AI Makerspace, which was originally using ArXiv and Duck Duck Go Search tools."
      ],
      "metadata": {
        "id": "zx4wK2PMxdWf"
      }
    }
  ]
}